{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6h1d5l89MlP8"
   },
   "source": [
    "**SEGMENTACIÓN AUTOMÁTICA DE NUCLEOS USANDO UNA U-NET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hdnk-92JK2a0"
   },
   "source": [
    "La segmentación automática de imágenes de microscopía es una tarea importante en el procesamiento y análisis de imágenes médicas. La detección de núcleos es uno de los ejemplos más relevantes: Si se pudiera realizar de forma totalmente automatizada, se aceleraría la investigación de casi todas las enfermedades, desde el cáncer de pulmón y las enfermedades cardíacas hasta los trastornos raros. Usaremos un dataset de kaggle. Usaremos solo una pequeña muestra que podeis descargar [aqui](https://api.cloud.ifca.es:8080/swift/v1/datalabbio/datos_segmentacion.zip), pero el dataset completo está en kaggle y lo podéis descargar [aqui](https://api.cloud.ifca.es:8080/swift/v1/datalabbio/datos_segmentacion.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88c8f888-4eb5-438e-8428-0d6f9280aa70",
    "_uuid": "3cf23599bb2587214d3f8b50d3b512bb025159f1",
    "colab_type": "text",
    "id": "ZE-Az6Xic3Qp"
   },
   "source": [
    "Vamos a utilizar una u-net para realizar segmentación semántica. Os recomiendo que leais [este artículo](https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47). Además, encontraréis en él referencias al artículo orignal de la u-net por si hay alguien interesado :-). La u-net tiene una parte de codificación y otra de decodificación, que es la que le confiera esa forma de U que da lugar a su nombre.\n",
    "![texto alternativo](https://miro.medium.com/max/1400/1*OkUrpDD6I0FpugA_bbYBJQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7h2RLl3Dd4HU"
   },
   "source": [
    "Vemos ahora un ejemplo de lo que queremos conseguir exactamente. Vemos una imagen de microscopio y debajo las imagenes de sus máscaras. Cuando la red esté entrenada, deberiamos poder meterle una imagen de microscopio nueva y que nos devuelva su máscara de capa donde en este caso habrá dos categorías: nucleo y no nucleo. Esta clasificación se hará pixel a pixel, y esto es justamente lo que se conoce como segmentación semántica. Esto nos permitiría contar núcleos de manera automática.\n",
    "\n",
    "![texto alternativo](https://dl.acm.org/cms/attachment/3e2d2318-76a6-420b-b428-fc84e7ef9dc0/tomm1601-12-f01.jpg)\n",
    "\n",
    "Como para esta práctica no vamos a tener acceso a todos los datos, solo me interesa que seais capaces de correr una u-net, que veais como se definen sus capas y entendais su arquitectura. No nos vamos a preocupar del resultado final porque para ello necesitariamos muchos más datos. \n",
    "\n",
    "Como métrica,para entrenar, vamos a utilizar la IoU media. Vimos lo que era la IoU (Intersection over Union) durante la clase de Machine Learning I, pero veamos aqui un pequeño recordatorio gráfico:\n",
    "![texto alternativo](https://pyimagesearch.com/wp-content/uploads/2016/09/iou_equation.png)\n",
    "\n",
    "Esto quiere decir que si lo hacemos perfecto, IoU sería igual a 1. La media de IoU es la media de la IoU para todas las imágenes del dataset. En esta práctica, y con las muestras que tenéis, aspiramos solo a tener un mean IoU entorno a 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "0kYKQvaEdpUL",
    "outputId": "ca89f717-154e-4eb7-ec35-91d058c1e485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "6b324c96-b92c-4c71-835a-cc6adb1c7a0c",
    "_uuid": "9d65868c23446ed123810c4187c0e598ce01c652",
    "colab": {},
    "colab_type": "code",
    "id": "9OdqZWGJc3Qr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow,imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Vamos a definir algunos parámetros\n",
    "BATCH_SIZE = 1 \n",
    "IMG_WIDTH = 128 \n",
    "IMG_HEIGHT = 128 \n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "#Pon el path a tu carpeta de drive donde están los datos\n",
    "TRAIN_PATH = '...'\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b2464b8e-77ba-44b1-8c78-06b1e690910d",
    "_uuid": "a3c37b92fa214f1be75ac3630927555ff40674b2",
    "colab_type": "text",
    "id": "oME2bPO1c3Qx"
   },
   "source": [
    "### *Preparando los datos*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "bb7da2b8-5921-4769-9bee-afab2135472d",
    "_uuid": "2ff390c2a99e276c65e34d9ed61208347cacafe2",
    "colab": {},
    "colab_type": "code",
    "id": "gX-tC-IxNEvb"
   },
   "outputs": [],
   "source": [
    "# Aqui obtenemos una lista con los nombres de los directorios donde se encuentran los datos\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "c6db52ac-98df-4e0f-bab2-b83565c0fde2",
    "_uuid": "ef50f72d80920e9b53c73919994199c0c9a8c955",
    "colab": {},
    "colab_type": "code",
    "id": "H_he3pnbc3Q2"
   },
   "outputs": [],
   "source": [
    "# Obtener las imagenes y las máscaras de capa\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "print('Obteniendo y cambiando el tamaño de las imagenes y las máscaras de capa (etiquetas) ... ')\n",
    "sys.stdout.flush()\n",
    "#Fijaos en lo útil que es la función tqdm que nos permite tener una barra de estado para ir viendo la evolución\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f70481c-7b7b-4f60-8d11-e0e36030697c",
    "_uuid": "1593b0eb0503758424ce1ec5ded8d59557d4d1df",
    "colab_type": "text",
    "id": "I5d-weO5c3Q6"
   },
   "source": [
    "### *Data augmentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "0e78cfea-5120-4c18-80a0-fd09964e024d",
    "_uuid": "7448169cf1949461f30735a89f96b4c4003dccea",
    "colab": {},
    "colab_type": "code",
    "id": "xZwty2oqc3Q7"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Crea los generadores y aplica data augmentation. \n",
    "#Mete modificaciones (rotaciones, reflejo especular, etc...) que tengan sentido en el caso de imagenes de microscopio. \n",
    "#Elige 4 o 5.\n",
    "image_datagen = image.ImageDataGenerator(...)\n",
    "mask_datagen = image.ImageDataGenerator(...)\n",
    "\n",
    "# Aqui cogemos el 80% de la muestra para training. \n",
    "#Le tenemos que dar la misma seed a la imagen y a la máscara para que aplique las transformaciones por igual.\n",
    "\n",
    "image_datagen.fit(X_train[:int(X_train.shape[0]*0.8)], augment=True, seed=seed)\n",
    "mask_datagen.fit(Y_train[:int(Y_train.shape[0]*0.8)], augment=True, seed=seed)\n",
    "\n",
    "x=image_datagen.flow(X_train[:int(X_train.shape[0]*0.8)],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n",
    "y=mask_datagen.flow(Y_train[:int(Y_train.shape[0]*0.8)],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n",
    "\n",
    "\n",
    "\n",
    "# Para validación vamos a hacer lo mismo, ahora nos quedaremos con el 20% **restante**\n",
    "image_datagen_val = image.ImageDataGenerator()\n",
    "mask_datagen_val = image.ImageDataGenerator()\n",
    "\n",
    "image_datagen_val.fit(..., augment=True, seed=seed)\n",
    "mask_datagen_val.fit(..., augment=True, seed=seed)\n",
    "\n",
    "x_val=image_datagen_val.flow(...,batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n",
    "y_val=mask_datagen_val.flow(...,batch_size=BATCH_SIZE,shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sIQFpXg4rD_d"
   },
   "source": [
    "Visualicemos las imágenes y las máscaras de capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "a6a85b26-695e-4975-b22f-80a79209c370",
    "_uuid": "22785cbdcdf3e7712ba2423a90869e44bd74e28c",
    "colab": {},
    "colab_type": "code",
    "id": "FF4u4cHCc3Q_"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "imshow(x.next()[0].astype(np.uint8))\n",
    "plt.show()\n",
    "imshow(np.squeeze(y.next()[0].astype(np.uint8)))\n",
    "plt.show()\n",
    "imshow(x_val.next()[0].astype(np.uint8))\n",
    "plt.show()\n",
    "imshow(np.squeeze(y_val.next()[0].astype(np.uint8)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "54ec711a-1380-426f-8223-b03a62c659a2",
    "_uuid": "a23269d50bba3f2521202ff835fd5a4d34c785e9",
    "colab": {},
    "colab_type": "code",
    "id": "cV2wviTuc3RC"
   },
   "outputs": [],
   "source": [
    "#Creamos un generador de train y de val que nos genere las imágenes y las máscaras\n",
    "train_generator = zip(x, y)\n",
    "val_generator = zip(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae011253-08b8-44db-8be9-c1092e171553",
    "_uuid": "17f9af12f2fc93a2e57c3cfdc3c122f97f1fa7e4",
    "colab_type": "text",
    "id": "p3RhL6y8c3RF"
   },
   "source": [
    "### *Construyendo el modelo u-net.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UCtsQA3TZDAD"
   },
   "source": [
    " La estructura es distinta a como lo solemos hacer, fijaos en que a cada capa se le va diciendo explícitamente cual es la capa de input que tiene que coger. Esto se hace así porque si os fijais, en una U-net, la parte de decodificación necesita concatenar como input varias capas (fijaos en el gráfico de arriba donde se muestra la u-net). Atención a la nueva manera de normalizar el input según va entrando en la red. Usaremos de función de activación la función elu (exponential linear unit). Más información sobre esta función de activación [aqui](https://medium.com/@krishnakalyan3/introduction-to-exponential-linear-unit-d3e2904b366c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "0f97a2d9-a9a0-4399-bbca-198cdda087b6",
    "_uuid": "ab499cefbbe8dc514c6347fe203d87eb7974adf0",
    "colab": {},
    "colab_type": "code",
    "id": "CRtpI8Tqc3RJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    " \n",
    "#Utiliza como metrica la IoU media (MeanIoU en Keras), y optimizador adam, y como función de pérdida ¿Qué función tiene sentido poner?\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer=..., loss=..., metrics=[...])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5d17d35a-753d-47c5-b1d7-7effa1af04a7",
    "_uuid": "a9378262b0194c0aa54df3e2ea5696b447f8ef83",
    "colab_type": "text",
    "id": "Z9fH_YBQc3RM"
   },
   "source": [
    "### *Entrenando*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "2cc45263-7607-4d9d-b0e0-88b3135ba60b",
    "_uuid": "440055f1d1feb25fe08f942d15257e2454d2022b",
    "colab": {},
    "colab_type": "code",
    "id": "UAlJZh7Hc3RM"
   },
   "outputs": [],
   "source": [
    "# Mete early stopping y entrena durante 10 épocas. Recuerda meter también el generador de validación.\n",
    "results = model.fit_generator(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e12a9f1-279f-4031-b8c5-4f825f84cc13",
    "_uuid": "168a4d55c79c92cd17a398cff13876fb0b32cdbf",
    "colab_type": "text",
    "id": "yVL4QV9wc3RP"
   },
   "source": [
    "### *Prediciendo*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jpf_BlKwq-K-"
   },
   "source": [
    "Vamos a ver como quedarían algunas de las muestras de validación. Para ello repite lo que has hecho arriba y coge el 20% final de X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "ef72a295-7187-41d6-9ecf-c5ee201f000d",
    "_uuid": "f9b92b3ce2079288fe8a2ed75f3c8679ee93113f",
    "colab": {},
    "colab_type": "code",
    "id": "E4VmqxX2c3RP"
   },
   "outputs": [],
   "source": [
    "# Predecir en train y en validación\n",
    "preds_val = model.predict(..., verbose=1)\n",
    "ix = random.randint(0, len(preds_val))\n",
    "imshow(X_train[...][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[...][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val[ix]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Practica_segmentacion.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
